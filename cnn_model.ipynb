{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vo4iq-cLo3I",
        "outputId": "a0f1274b-f24f-4bfc-bcd4-6aabb37c2932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "total 1.5G\n",
            "drwx------ 2 root root 4.0K Mar  5 19:37  Ants_Simulation\n",
            "drwx------ 2 root root 4.0K Aug 16 04:41 'Colab Notebooks'\n",
            "-rw------- 1 root root 1.3G Aug  7 09:59  images.hdf5\n",
            "-rw------- 1 root root 246M Aug  7 09:57  subject_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# This error is often transient and can be resolved by retrying.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List files in your Drive\n",
        "!ls -lh /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYjlISATL3BS",
        "outputId": "2a790e6b-fea1-445c-8c7e-4e49ac45861a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-395030041.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"/content/drive/MyDrive/subject_data.csv\")\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/subject_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p6QloHcEMAHM"
      },
      "outputs": [],
      "source": [
        "# mobile_cnn_augmented_split.py\n",
        "import os, io, random\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import h5py\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3OvihcjPNGDL"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# User-editable paths & params\n",
        "# ---------------------------\n",
        "SUBJECT_CSV = \"/content/drive/MyDrive/subject_data.csv\"   # change if needed\n",
        "IMAGES_HDF5 = \"/content/drive/MyDrive/images.hdf5\"       # change if needed\n",
        "OUTPUT_DIR = \"./cnn_mobilenet_augmented_split\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 256        # reduce if OOM\n",
        "EPOCHS = 2\n",
        "RANDOM_SEED = 42\n",
        "FOCAL_GAMMA = 2.0\n",
        "FOCAL_ALPHA = 0.9\n",
        "\n",
        "# class1 split ratios (explicit as requested)\n",
        "POS_TRAIN_FRAC = 0.65\n",
        "POS_VAL_FRAC   = 0.10\n",
        "POS_TEST_FRAC  = 0.25\n",
        "\n",
        "# same splits applied to negatives for consistency (you can change if desired)\n",
        "NEG_TRAIN_FRAC = 0.55\n",
        "NEG_VAL_FRAC   = 0.15\n",
        "NEG_TEST_FRAC  = 0.30\n",
        "\n",
        "# augmentation intensity for positives\n",
        "HEAVY_AUG = True   # used by generator for positive samples\n",
        "\n",
        "# reproducibility\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "k-PkTw77NKSN"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Load CSV and HDF5\n",
        "# ---------------------------\n",
        "df = pd.read_csv(SUBJECT_CSV, low_memory=False)\n",
        "hf = h5py.File(IMAGES_HDF5, 'r')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S0-bwpCaNNl6"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Robust decode helper (supports bytes or numeric arrays)\n",
        "# ---------------------------\n",
        "def decode_bytes_image(raw_bytes):\n",
        "    # raw_bytes: python bytes or np.bytes_\n",
        "    try:\n",
        "        img_tensor = tf.io.decode_jpeg(raw_bytes, channels=3)\n",
        "        return img_tensor.numpy()  # uint8 HxWx3\n",
        "    except Exception:\n",
        "        # fallback using PIL\n",
        "        try:\n",
        "            return np.asarray(Image.open(io.BytesIO(raw_bytes)).convert(\"RGB\"), dtype=np.uint8)\n",
        "        except Exception as e:\n",
        "            raise\n",
        "\n",
        "def ensure_uint8_array(arr):\n",
        "    # bytes-like\n",
        "    if isinstance(arr, (bytes, np.bytes_)):\n",
        "        return decode_bytes_image(arr)\n",
        "    # string/object dtype -> try to extract raw bytes\n",
        "    if hasattr(arr, 'dtype') and (arr.dtype.kind == 'S' or arr.dtype.kind == 'O'):\n",
        "        try:\n",
        "            b = arr.tobytes()\n",
        "            return decode_bytes_image(b)\n",
        "        except Exception:\n",
        "            try:\n",
        "                b = arr.item()\n",
        "                return decode_bytes_image(b)\n",
        "            except Exception:\n",
        "                pass\n",
        "    # numeric ndarray\n",
        "    if isinstance(arr, np.ndarray):\n",
        "        if arr.ndim == 3:\n",
        "            if arr.shape[-1] == 3:\n",
        "                return arr.astype(np.uint8)\n",
        "            if arr.shape[0] == 3:\n",
        "                return np.transpose(arr, (1,2,0)).astype(np.uint8)\n",
        "        if arr.ndim == 2:\n",
        "            # grayscale -> convert to 3-channel\n",
        "            return np.stack([arr,arr,arr], axis=-1).astype(np.uint8)\n",
        "    # last-resort: try converting to bytes\n",
        "    try:\n",
        "        b = np.asarray(arr).tobytes()\n",
        "        return decode_bytes_image(b)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Could not decode HDF5 entry: dtype={getattr(arr,'dtype',None)}, shape={getattr(arr,'shape',None)}; err={e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "q7l293s0OPDW"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Light and heavy augmentations (numpy/tf) - robust across envs\n",
        "# ---------------------------\n",
        "def random_resized_crop(img, out_size=IMG_SIZE, scale=(0.7, 1.0)):\n",
        "    h, w = img.shape[:2]\n",
        "    s = random.uniform(scale[0], scale[1])\n",
        "    new_h, new_w = max(1, int(h * s)), max(1, int(w * s))\n",
        "    top = random.randint(0, h - new_h) if new_h < h else 0\n",
        "    left = random.randint(0, w - new_w) if new_w < w else 0\n",
        "    cropped = img[top: top + new_h, left: left + new_w]\n",
        "    resized = tf.image.resize(cropped, (out_size, out_size), method='bilinear').numpy()\n",
        "    return resized\n",
        "\n",
        "def random_flip(img):\n",
        "    return np.fliplr(img).copy() if random.random() < 0.5 else img\n",
        "\n",
        "def random_rotate_90(img):\n",
        "    if random.random() < 0.15:\n",
        "        k = random.choice([1,2,3])\n",
        "        return np.ascontiguousarray(np.rot90(img, k))\n",
        "    return img\n",
        "\n",
        "def random_brightness_contrast(img, brightness_delta=32, contrast_low=0.85, contrast_high=1.15):\n",
        "    delta = random.uniform(-brightness_delta, brightness_delta)\n",
        "    img = img + delta\n",
        "    factor = random.uniform(contrast_low, contrast_high)\n",
        "    mean = img.mean(axis=(0,1), keepdims=True)\n",
        "    img = (img - mean) * factor + mean\n",
        "    return img\n",
        "\n",
        "def random_zoom(img, min_zoom=1.0, max_zoom=1.2):\n",
        "    # zoom by cropping center then resizing back (zoom in)\n",
        "    if random.random() < 0.3:\n",
        "        h, w = img.shape[:2]\n",
        "        zm = random.uniform(min_zoom, max_zoom)\n",
        "        crop_h = int(h / zm)\n",
        "        crop_w = int(w / zm)\n",
        "        top = (h - crop_h) // 2\n",
        "        left = (w - crop_w) // 2\n",
        "        crop = img[top:top+crop_h, left:left+crop_w]\n",
        "        return tf.image.resize(crop, (h, w)).numpy()\n",
        "    return img\n",
        "\n",
        "def clip_cast(img):\n",
        "    return np.clip(img, 0, 255).astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eJxfcWBzOUbc"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Loader: decode, augment-level-controlled, preprocess\n",
        "# ---------------------------\n",
        "def load_image_by_id(isic_id, augment_level='none'):\n",
        "    \"\"\"\n",
        "    augment_level: 'none' | 'light' | 'heavy'\n",
        "    \"\"\"\n",
        "    key = str(isic_id)\n",
        "    if key not in hf:\n",
        "        # missing -> return zeros\n",
        "        img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
        "    else:\n",
        "        raw = hf[key][()]\n",
        "        img = ensure_uint8_array(raw)\n",
        "\n",
        "    if augment_level == 'none':\n",
        "        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE), method='bilinear').numpy()\n",
        "    elif augment_level == 'light':\n",
        "        img = random_resized_crop(img, out_size=IMG_SIZE, scale=(0.8, 1.0))\n",
        "        img = random_flip(img)\n",
        "        img = random_brightness_contrast(img, brightness_delta=16, contrast_low=0.9, contrast_high=1.1)\n",
        "    elif augment_level == 'heavy':\n",
        "        img = random_resized_crop(img, out_size=IMG_SIZE, scale=(0.5, 1.0))\n",
        "        img = random_flip(img)\n",
        "        img = random_rotate_90(img)\n",
        "        img = random_zoom(img, min_zoom=1.0, max_zoom=1.4)\n",
        "        img = random_brightness_contrast(img, brightness_delta=32, contrast_low=0.8, contrast_high=1.2)\n",
        "    else:\n",
        "        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE), method='bilinear').numpy()\n",
        "\n",
        "    img = clip_cast(img)\n",
        "    img = mobilenet_preprocess(img)   # MobileNet preprocessing\n",
        "    return img\n",
        "\n",
        "# ---------------------------\n",
        "# Custom f1 metric (tensor-based)\n",
        "# ---------------------------\n",
        "def f1_metric(y_true, y_pred):\n",
        "    y_pred_bin = tf.cast(y_pred > 0.5, tf.float32)\n",
        "    tp = tf.reduce_sum(y_true * y_pred_bin)\n",
        "    fp = tf.reduce_sum((1 - y_true) * y_pred_bin)\n",
        "    fn = tf.reduce_sum(y_true * (1 - y_pred_bin))\n",
        "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
        "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
        "    return 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsAAKC1dOzqd",
        "outputId": "e719a22d-8c86-46aa-effc-006c5a7cbe83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splits sizes -> train: 220621 val: 60139 test: 120299\n",
            "Pos counts -> train,val,test: 255 39 99\n",
            "Neg counts -> train,val,test: 220366 60100 120200\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# Create per-class splits with required positive-class proportions\n",
        "# ---------------------------\n",
        "pos_df = df[df['target'] == 1].sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "neg_df = df[df['target'] == 0].sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "def split_class_df(class_df, train_frac, val_frac, test_frac):\n",
        "    n = len(class_df)\n",
        "    n_train = int(np.round(n * train_frac))\n",
        "    n_val = int(np.round(n * val_frac))\n",
        "    # ensure sum not exceed n\n",
        "    n_test = n - n_train - n_val\n",
        "    train_part = class_df.iloc[:n_train].copy()\n",
        "    val_part = class_df.iloc[n_train:n_train + n_val].copy()\n",
        "    test_part = class_df.iloc[n_train + n_val:].copy()\n",
        "    return train_part, val_part, test_part\n",
        "\n",
        "pos_train, pos_val, pos_test = split_class_df(pos_df, POS_TRAIN_FRAC, POS_VAL_FRAC, POS_TEST_FRAC)\n",
        "neg_train, neg_val, neg_test = split_class_df(neg_df, NEG_TRAIN_FRAC, NEG_VAL_FRAC, NEG_TEST_FRAC)\n",
        "\n",
        "train_df = pd.concat([pos_train, neg_train], axis=0).sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "val_df   = pd.concat([pos_val,   neg_val],   axis=0).sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "test_df  = pd.concat([pos_test,  neg_test],  axis=0).sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "print(\"Splits sizes -> train:\", len(train_df), \"val:\", len(val_df), \"test:\", len(test_df))\n",
        "print(\"Pos counts -> train,val,test:\", len(pos_train), len(pos_val), len(pos_test))\n",
        "print(\"Neg counts -> train,val,test:\", len(neg_train), len(neg_val), len(neg_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gyrjMlFGQPS1"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Balanced-batch generator with 60% pos, 40% neg\n",
        "# ---------------------------\n",
        "def balanced_batch_generator(df_subset, batch_size=BATCH_SIZE, augment_pos_heavy=HEAVY_AUG):\n",
        "    pos_ids = df_subset[df_subset['target'] == 1]['isic_id'].astype(str).tolist()\n",
        "    neg_ids = df_subset[df_subset['target'] == 0]['isic_id'].astype(str).tolist()\n",
        "    if len(pos_ids) == 0 or len(neg_ids) == 0:\n",
        "        raise ValueError(\"both classes must exist in df_subset\")\n",
        "\n",
        "    # compute number of pos/neg per batch\n",
        "    pos_count = int(np.round(batch_size * 0.6))\n",
        "    neg_count = batch_size - pos_count\n",
        "\n",
        "    while True:\n",
        "        # sample positives (with replacement if needed)\n",
        "        sample_pos = (\n",
        "            random.sample(pos_ids, pos_count)\n",
        "            if len(pos_ids) >= pos_count\n",
        "            else random.choices(pos_ids, k=pos_count)\n",
        "        )\n",
        "        # sample negatives (with replacement if needed)\n",
        "        sample_neg = (\n",
        "            random.sample(neg_ids, neg_count)\n",
        "            if len(neg_ids) >= neg_count\n",
        "            else random.choices(neg_ids, k=neg_count)\n",
        "        )\n",
        "\n",
        "        batch_ids = sample_pos + sample_neg\n",
        "        random.shuffle(batch_ids)\n",
        "\n",
        "        X, y = [], []\n",
        "        for iid in batch_ids:\n",
        "            if iid in sample_pos:\n",
        "                level = 'heavy' if augment_pos_heavy else 'light'\n",
        "                label = 1.0\n",
        "            else:\n",
        "                level = 'none'  # negatives kept raw\n",
        "                label = 0.0\n",
        "            img = load_image_by_id(iid, augment_level=level)\n",
        "            X.append(img)\n",
        "            y.append(label)\n",
        "\n",
        "        X = np.stack(X)\n",
        "        y = np.array(y, dtype=np.float32)\n",
        "        yield X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "H_vEOPJSQPm_"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Build MobileNetV2 model with GAP + GMP\n",
        "# ---------------------------\n",
        "def build_model(trainable_backbone=False, lr=1e-3):\n",
        "    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # backbone WITHOUT built-in pooling so we can do GAP+GMP\n",
        "    backbone = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_tensor=inp  # uses 'inp' as input\n",
        "    )\n",
        "    backbone.trainable = trainable_backbone\n",
        "\n",
        "    # apply both poolings and concatenate\n",
        "    feat = backbone.output\n",
        "    gap = layers.GlobalAveragePooling2D(name=\"gap\")(feat)\n",
        "    gmp = layers.GlobalMaxPooling2D(name=\"gmp\")(feat)\n",
        "    x = layers.Concatenate(name=\"gap_gmp_concat\")([gap, gmp])\n",
        "\n",
        "    # your dense stack (unchanged)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    out = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.005),\n",
        "        loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=FOCAL_GAMMA, alpha = FOCAL_ALPHA),\n",
        "        metrics=[\n",
        "            tf.keras.metrics.AUC(curve='ROC', name='auc_roc'),\n",
        "            tf.keras.metrics.AUC(curve='PR',  name='auc_pr'),\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            f1_metric\n",
        "        ]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "r6x-KqBFTQlE"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Callbacks\n",
        "# ---------------------------\n",
        "logdir = os.path.join(OUTPUT_DIR, \"logs_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "os.makedirs(logdir, exist_ok=True)\n",
        "ckpt_path = os.path.join(OUTPUT_DIR, \"best_model.weights.h5\")\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_auc_pr', patience=4, mode='max', restore_best_weights=True),\n",
        "    ModelCheckpoint(ckpt_path, monitor='val_auc_pr', mode='max', save_best_only=True, save_weights_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_auc_pr', mode='max', factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
        "    tf.keras.callbacks.CSVLogger(os.path.join(logdir, \"training_log.csv\")),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gqA-q6ZTV5x",
        "outputId": "867f4688-1a71-4994-b5a0-b2987039a44f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3696724710.py:8: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  backbone = MobileNetV2(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training head: steps_per_epoch 1721 val_steps 234\n",
            "Epoch 1/2\n",
            "\u001b[1m1721/1721\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - auc_pr: 0.9794 - auc_roc: 0.9717 - f1_metric: 0.6037 - loss: 0.0561 - precision: 0.9319 - recall: 0.9394\n",
            "Epoch 1: val_auc_pr improved from -inf to 0.92444, saving model to ./cnn_mobilenet_augmented_split/best_model.weights.h5\n",
            "\u001b[1m1721/1721\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3089s\u001b[0m 2s/step - auc_pr: 0.9794 - auc_roc: 0.9717 - f1_metric: 0.6037 - loss: 0.0561 - precision: 0.9319 - recall: 0.9394 - val_auc_pr: 0.9244 - val_auc_roc: 0.8958 - val_f1_metric: 0.4894 - val_loss: 0.2758 - val_precision: 0.9267 - val_recall: 0.6365 - learning_rate: 0.0050\n",
            "Epoch 2/2\n",
            "\u001b[1m 444/1721\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33:17\u001b[0m 2s/step - auc_pr: 0.9964 - auc_roc: 0.9950 - f1_metric: 0.6032 - loss: 0.0224 - precision: 0.9734 - recall: 0.9790"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# Train: Stage 1 (head only)\n",
        "# ---------------------------\n",
        "model = build_model(trainable_backbone=False, lr=1e-3)\n",
        "steps = max(1, len(train_df[train_df['target']==0]) // (BATCH_SIZE // 2))\n",
        "val_steps = max(1, len(val_df) // BATCH_SIZE)\n",
        "print(\"Training head: steps_per_epoch\", steps, \"val_steps\", val_steps)\n",
        "\n",
        "model.fit(\n",
        "    balanced_batch_generator(train_df, batch_size=BATCH_SIZE, augment_pos_heavy=True),\n",
        "    steps_per_epoch=steps,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=balanced_batch_generator(val_df, batch_size=BATCH_SIZE, augment_pos_heavy=False),\n",
        "    validation_steps=val_steps,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-GFr7WHTYah"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Optionally Stage 2: fine-tune top of backbone\n",
        "# ---------------------------\n",
        "# Example: unfreeze last N layers of backbone and fine-tune with small lr\n",
        "def unfreeze_top_layers(model, backbone_layer_name=\"mobilenetv2_1.00_224\", n_unfreeze=30):\n",
        "    # find backbone by class\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.Model):\n",
        "            backbone = layer\n",
        "            break\n",
        "    else:\n",
        "        backbone = None\n",
        "    if backbone is None:\n",
        "        print(\"Backbone model not found; skip unfreeze.\")\n",
        "        return model\n",
        "    # Freeze all, then unfreeze top n_unfreeze\n",
        "    for l in backbone.layers:\n",
        "        l.trainable = False\n",
        "    for l in backbone.layers[-n_unfreeze:]:\n",
        "        if not isinstance(l, tf.keras.layers.BatchNormalization):\n",
        "            l.trainable = True\n",
        "    # recompile with lower lr\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                  loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=FOCAL_GAMMA),\n",
        "                  metrics=[tf.keras.metrics.AUC(curve='PR', name='auc_pr'), tf.keras.metrics.AUC(curve='ROC', name='auc_roc'), f1_metric, \"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lo0ej2VTc_8"
      },
      "outputs": [],
      "source": [
        "# Uncomment to fine-tune:\n",
        "'''\n",
        "model = unfreeze_top_layers(model, n_unfreeze=35)\n",
        "model.fit(  balanced_batch_generator(train_df, batch_size=BATCH_SIZE, augment_pos_heavy=True),\n",
        "    steps_per_epoch=steps,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=balanced_batch_generator(val_df, batch_size=BATCH_SIZE, augment_pos_heavy=False),\n",
        "    validation_steps=val_steps,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        "            )\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36hNrIxUTdI3"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Evaluate final on test set\n",
        "# ---------------------------\n",
        "def evaluate_on_df(model, df_eval):\n",
        "    ids = df_eval['isic_id'].astype(str).tolist()\n",
        "    ys = df_eval['target'].values\n",
        "    preds = []\n",
        "    for i in range(0, len(ids), BATCH_SIZE):\n",
        "        batch = ids[i:i+BATCH_SIZE]\n",
        "        X = np.stack([load_image_by_id(idv, augment_level='none') for idv in batch])\n",
        "        p = model.predict(X, verbose=0).ravel().tolist()\n",
        "        preds.extend(p)\n",
        "    preds = np.array(preds)\n",
        "    # metrics\n",
        "    if len(np.unique(ys)) < 2:\n",
        "        return {\"roc_auc\": None, \"pr_auc\": None, \"best_f1\": None}\n",
        "    roc = roc_auc_score(ys, preds)\n",
        "    pr = average_precision_score(ys, preds)\n",
        "    prec, rec, th = precision_recall_curve(ys, preds)\n",
        "    best_f1 = float(np.max(2*prec*rec/(prec+rec+1e-12))) if len(prec)>0 else 0.0\n",
        "    return {\"roc_auc\": float(roc), \"pr_auc\": float(pr), \"best_f1\": best_f1}\n",
        "\n",
        "metrics = evaluate_on_df(model, test_df)\n",
        "print(\"Test metrics:\", metrics)\n",
        "\n",
        "# cleanup\n",
        "hf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UyIgcG1kTdRh"
      },
      "outputs": [],
      "source": [
        "pos_weight = len(neg_train) / len(pos_train)\n",
        "FOCAL_ALPHA = pos_weight / (1 + pos_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bncw3FiHWfTE",
        "outputId": "68c22220-b87e-466b-8237-cc2c78f9a90d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9988441716790333"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "FOCAL_ALPHA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed3s4wfWWhN7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
