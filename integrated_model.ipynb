{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4541dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, recall_score, confusion_matrix, accuracy_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db3cc676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:    \n",
    "    # paths\n",
    "    METADATA_PATH = 'subject_data.csv'\n",
    "    IMAGES_PATH = 'images.hdf5'\n",
    "\n",
    "    # Undersampling and Oversampling\n",
    "    # Ratio of negative to positive samples\n",
    "    ## In original training data distribution is:\n",
    "        ## target\n",
    "        ## 0    400666\n",
    "        ## 1       393\n",
    "        \n",
    "    NEG_RATIO = 50 #50\n",
    "    SMOTE = True # ENCODE_CAT must be True\n",
    "    SMOTE_RATIO = 0.3\n",
    "    K_NEIGHBORS = 2\n",
    "    \n",
    "    # Features to use\n",
    "    METADATA_FEATURES = True # Initial features\n",
    "    GROUPBY_FEATURES = True\n",
    "    IMAGE_FEATURES = False # Add isic_id column if True\n",
    "    \n",
    "    # Early stopping rounds\n",
    "    EARLY_STOP = 30\n",
    "    \n",
    "    # Number of KFold splits\n",
    "    N_SPLITS = 5 \n",
    "    \n",
    "    # Testing encode or not cat_cols\n",
    "    ENCODE_CAT = True\n",
    "    \n",
    "    # LightGBM parameters\n",
    "    lgb_params = {\n",
    "        'objective': \"binary\",\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': \"gbdt\",\n",
    "        'depth': None,\n",
    "        'n_estimators': 200,\n",
    "        'learning_rate': 0.05,    \n",
    "        'lambda_l1': 0.0005, \n",
    "        'lambda_l2': 8, \n",
    "        'num_leaves': 130, \n",
    "        'feature_fraction': 0.5, \n",
    "        'bagging_fraction': 1, \n",
    "        'bagging_freq': 6,\n",
    "        'min_child_samples': 60\n",
    "    }\n",
    "\n",
    "    # XGBoost parameters\n",
    "    xgb_params = {\n",
    "        'verbosity': 0,\n",
    "        'depth': None,\n",
    "        'n_estimators': 200,\n",
    "        'learning_rate': 0.05,    \n",
    "        'lambda_l1': 0.0005, \n",
    "        'lambda_l2': 8, \n",
    "        'num_leaves': 130, \n",
    "        'feature_fraction': 0.5, \n",
    "        'bagging_fraction': 1, \n",
    "        'bagging_freq': 6,\n",
    "        'min_child_samples': 60\n",
    "    }\n",
    "\n",
    "    # TabNet model\n",
    "    tabnet_params = {\n",
    "        'n_d': 16,\n",
    "        'n_a': 16,\n",
    "        'n_steps': 5,\n",
    "        'gamma': 1.5,\n",
    "        'lambda_sparse': 1e-4,\n",
    "        'optimizer_fn': torch.optim.Adam,\n",
    "        'optimizer_params': dict(lr=2e-2),\n",
    "        'mask_type': 'sparsemax',\n",
    "        'verbose': 10\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f529ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing:    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def filter_data(self, path):\n",
    "        \"\"\"\n",
    "        Reads CSV into pandas DataFrame and drops redundant columns.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "\n",
    "        drop_cols = [\n",
    "            'isic_id',  # Redundant for loading train data\n",
    "            'image_type',  # Only one unique value in train metadata\n",
    "            'tbp_lv_location_simple',  # Similar to 'tbp_lv_location'\n",
    "            'copyright_license',  # Not useful for lesion classification\n",
    "\n",
    "            # Predictive Features\n",
    "            'lesion_id',\n",
    "            'iddx_full',\n",
    "            'iddx_1', \n",
    "            'iddx_2', \n",
    "            'iddx_3',\n",
    "            'iddx_4', \n",
    "            'iddx_5', \n",
    "            'mel_mitotic_index', \n",
    "            'mel_thick_mm',\n",
    "        ]\n",
    "\n",
    "        # Drop only columns that exist\n",
    "        df = df.drop(columns=[col for col in drop_cols if col in df.columns], errors='ignore')\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def set_datatypes(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Converts column dtypes: handle NAs, cast numeric & categorical columns.\n",
    "        \"\"\"\n",
    "        # Handle NA values in 'age_approx'\n",
    "        if 'age_approx' in df.columns:\n",
    "            df['age_approx'] = df['age_approx'].replace('NA', -1)\n",
    "\n",
    "        # Integer columns\n",
    "        int_cols = ['target', 'age_approx', 'tbp_lv_symm_2axis_angle']\n",
    "        for col in int_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int16')\n",
    "\n",
    "        # Float columns\n",
    "        float_cols = [\n",
    "            'clin_size_long_diam_mm',\n",
    "            'tbp_lv_A', \n",
    "            'tbp_lv_Aext', \n",
    "            'tbp_lv_B', \n",
    "            'tbp_lv_Bext',\n",
    "            'tbp_lv_C', \n",
    "            'tbp_lv_Cext', \n",
    "            'tbp_lv_H', \n",
    "            'tbp_lv_Hext', \n",
    "            'tbp_lv_L', \n",
    "            'tbp_lv_Lext',\n",
    "            'tbp_lv_areaMM2', \n",
    "            'tbp_lv_area_perim_ratio', \n",
    "            'tbp_lv_color_std_mean',\n",
    "            'tbp_lv_deltaA', \n",
    "            'tbp_lv_deltaB', \n",
    "            'tbp_lv_deltaL', \n",
    "            'tbp_lv_deltaLB',\n",
    "            'tbp_lv_deltaLBnorm', \n",
    "            'tbp_lv_eccentricity', \n",
    "            'tbp_lv_minorAxisMM',\n",
    "            'tbp_lv_nevi_confidence', \n",
    "            'tbp_lv_norm_border', \n",
    "            'tbp_lv_norm_color',\n",
    "            'tbp_lv_perimeterMM', \n",
    "            'tbp_lv_radial_color_std_max', \n",
    "            'tbp_lv_stdL', \n",
    "            'tbp_lv_stdLExt',\n",
    "            'tbp_lv_symm_2axis', \n",
    "            'tbp_lv_x', \n",
    "            'tbp_lv_y', \n",
    "            'tbp_lv_z'\n",
    "        ]\n",
    "        for col in float_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
    "\n",
    "        # Categorical columns\n",
    "        cat_cols = [\n",
    "            'sex', \n",
    "            'anatom_site_general', \n",
    "            'tbp_tile_type', \n",
    "            'tbp_lv_location', \n",
    "            'attribution'\n",
    "        ]\n",
    "        for col in cat_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def initial_processing(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Applies full processing pipeline to the DataFrame.\n",
    "        \"\"\"\n",
    "        df = self.filter_data(df)\n",
    "        df = self.set_datatypes(df)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "059d018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def feature_engineering(self, df):        \n",
    "        # Malignant v/s Benign Predictive Features from Perplexity Suggestions\n",
    "        \n",
    "        df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "        df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
    "        df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "        df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "        df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"]**2 + df[\"tbp_lv_deltaB\"]**2 + df[\"tbp_lv_deltaL\"]**2)\n",
    "        df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "        df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "        df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "        df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "        df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "        df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "        df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "        df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "        df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "        df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
    "        df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "        df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "        df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "        df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"]**2 + df[\"tbp_lv_deltaB\"]**2 + df[\"tbp_lv_deltaL\"]**2) / 3)\n",
    "        df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "        df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "        df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "        df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "        \n",
    "        # Handling error indicators\n",
    "        df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "        df[\"color_uniformity\"] = df[\"color_uniformity\"].replace([np.nan, np.inf, -np.inf], 0)\n",
    "        \n",
    "        df[\"combined_anatomical_site\"] = (df[\"anatom_site_general\"].astype(str) + \"_\" + df[\"tbp_lv_location\"].astype(str)).astype(\"category\")\n",
    "        df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "        df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])        \n",
    "        df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "        df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "        df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "        df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "        df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "        df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "        df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n",
    "        df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "        df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n",
    "        df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def grouped_feature_engineering(self, df):\n",
    "        # 1. Ratios within age_approx groups\n",
    "        df['tbp_lv_ratio_A'] = (\n",
    "            df['tbp_lv_A'] / (df['tbp_lv_Aext'] * df.groupby('age_approx')['tbp_lv_A'].transform('min'))\n",
    "        ).astype('float32')\n",
    "\n",
    "        df['tbp_lv_ratio_B'] = (\n",
    "            df['tbp_lv_B'] / (df['tbp_lv_Bext'] * df.groupby('age_approx')['tbp_lv_B'].transform('min'))\n",
    "        ).astype('float32')\n",
    "\n",
    "        df['tbp_lv_ratio_C'] = (\n",
    "            df['tbp_lv_C'] / (df['tbp_lv_Cext'] * df.groupby('age_approx')['tbp_lv_C'].transform('min'))\n",
    "        ).astype('float32')\n",
    "\n",
    "        df['tbp_lv_ratio_H'] = (\n",
    "            df['tbp_lv_H'] / (df['tbp_lv_Hext'] * df.groupby('age_approx')['tbp_lv_H'].transform('min'))\n",
    "        ).astype('float32')\n",
    "\n",
    "        df['tbp_lv_ratio_L'] = (\n",
    "            df['tbp_lv_L'] / (df['tbp_lv_Lext'] * df.groupby('age_approx')['tbp_lv_L'].transform('min'))\n",
    "        ).astype('float32')\n",
    "\n",
    "        # 2. Contrast\n",
    "        df['tbp_lv_contrast_A'] = (df['tbp_lv_A'] - df['tbp_lv_Aext']).astype('float32')\n",
    "        df['tbp_lv_contrast_B'] = (df['tbp_lv_B'] - df['tbp_lv_Bext']).astype('float32')\n",
    "        df['tbp_lv_contrast_C'] = (df['tbp_lv_C'] - df['tbp_lv_Cext']).astype('float32')\n",
    "        df['tbp_lv_contrast_H'] = (df['tbp_lv_H'] - df['tbp_lv_Hext']).astype('float32')\n",
    "        df['tbp_lv_contrast_L'] = (df['tbp_lv_L'] - df['tbp_lv_Lext']).astype('float32')\n",
    "\n",
    "        # 3. Patient-level ratios\n",
    "        for col in ['tbp_lv_ratio_A', 'tbp_lv_ratio_B', 'tbp_lv_ratio_C', 'tbp_lv_ratio_H', 'tbp_lv_ratio_L']:\n",
    "            df[f'tbp_lv_patient_{col.split(\"_\", 2)[-1]}'] = (\n",
    "                df[col] / df.groupby('patient_id')[col].transform('mean')\n",
    "            ).astype('float32')\n",
    "\n",
    "        # 4. Patient-level contrasts\n",
    "        for col in ['tbp_lv_contrast_A', 'tbp_lv_contrast_B', 'tbp_lv_contrast_C', 'tbp_lv_contrast_H', 'tbp_lv_contrast_L']:\n",
    "            df[f'tbp_lv_patient_{col.split(\"_\", 2)[-1]}'] = (\n",
    "                df[col] / df.groupby('patient_id')[col].transform('mean')\n",
    "            ).astype('float32')\n",
    "\n",
    "        # 5. Age-level ratios\n",
    "        for col in ['tbp_lv_ratio_A', 'tbp_lv_ratio_B', 'tbp_lv_ratio_C', 'tbp_lv_ratio_H', 'tbp_lv_ratio_L']:\n",
    "            df[f'tbp_lv_age_{col.split(\"_\", 2)[-1]}'] = (\n",
    "                df[col] / df.groupby('age_approx')[col].transform('mean')\n",
    "            ).astype('float32')\n",
    "\n",
    "        # 6. Age-level contrasts\n",
    "        for col in ['tbp_lv_contrast_A', 'tbp_lv_contrast_B', 'tbp_lv_contrast_C', 'tbp_lv_contrast_H', 'tbp_lv_contrast_L']:\n",
    "            df[f'tbp_lv_age_{col.split(\"_\", 2)[-1]}'] = (\n",
    "                df[col] / df.groupby('age_approx')[col].transform('mean')\n",
    "            ).astype('float32')\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def add_image_features(self, file_path):\n",
    "        img_df = pd.read_csv(file_path)\n",
    "        if \"isic_id\" in img_df.columns:\n",
    "            img_df = img_df.drop(columns=[\"isic_id\"])\n",
    "        return img_df\n",
    "    \n",
    "    def extract_cat_cols(self, df):\n",
    "        return df.select_dtypes(include=[\"category\"]).columns.tolist()\n",
    "    \n",
    "    def downsample_data(self, df, neg_ratio=None, is_train=True):\n",
    "        if is_train:\n",
    "            p_cases = df[df[\"target\"] == 1]\n",
    "            n_cases = df[df[\"target\"] == 0]\n",
    "            if neg_ratio is not None:\n",
    "                N = int(len(p_cases) * neg_ratio)\n",
    "                n_cases = n_cases.sample(n=N, random_state=23)\n",
    "            df = pd.concat([n_cases, p_cases], ignore_index=True)\n",
    "        return df\n",
    "    \n",
    "    def remove_null_features(self, df, is_train=True):\n",
    "        if is_train:\n",
    "            df = df.dropna(how='any')\n",
    "        return df\n",
    "\n",
    "    def process_data(self, df, neg_ratio=None, is_train=True, img_feat_path=None):\n",
    "        if CONFIG.METADATA_FEATURES:\n",
    "            df = self.feature_engineering(df)        \n",
    "        if CONFIG.GROUPBY_FEATURES:\n",
    "            df = self.grouped_feature_engineering(df)    \n",
    "        if CONFIG.IMAGE_FEATURES:\n",
    "            df = self.add_image_features(img_feat_path)        \n",
    "        cat_cols = self.extract_cat_cols(df)        \n",
    "        if not CONFIG.IMAGE_FEATURES:\n",
    "            df = self.downsample_data(df, neg_ratio, is_train)\n",
    "\n",
    "        if is_train:\n",
    "            df = self.remove_null_features(df, is_train)\n",
    "        \n",
    "        return df, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73b3a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Processing()\n",
    "df = p.initial_processing(CONFIG.METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "665c5b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    400666\n",
       "1       393\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06218e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL DATASET INFORMATION:\n",
      "Shape: (19030, 109)\n",
      "Number of integer columns: 0\n",
      "Number of float columns: 99\n",
      "Number of categorical columns: 6\n",
      "Number of object columns: 1\n",
      "Total number of nulls in the DataFrame: 0\n",
      "\n",
      "Final categorical columns: \n",
      "['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'attribution', 'combined_anatomical_site']\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineering()\n",
    "data, cat_cols = fe.process_data(df.copy(), CONFIG.NEG_RATIO, img_feat_path=CONFIG.IMAGES_PATH)\n",
    "\n",
    "def print_df_info(df):\n",
    "    # Count the number of columns by data type\n",
    "    int_cols = df.select_dtypes(include=['int']).shape[1]\n",
    "    float_cols = df.select_dtypes(include=['float']).shape[1]\n",
    "    cat_cols = df.select_dtypes(include=['category']).shape[1]\n",
    "    obj_cols = df.select_dtypes(include=['object']).shape[1]\n",
    "\n",
    "    # Calculate the total number of nulls in the DataFrame\n",
    "    total_nulls = df.isnull().sum().sum()\n",
    "    shape = df.shape\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Shape: {shape}\")\n",
    "    print(f\"Number of integer columns: {int_cols}\")\n",
    "    print(f\"Number of float columns: {float_cols}\")\n",
    "    print(f\"Number of categorical columns: {cat_cols}\")\n",
    "    print(f\"Number of object columns: {obj_cols}\")\n",
    "    print(f\"Total number of nulls in the DataFrame: {total_nulls}\")\n",
    "\n",
    "\n",
    "print(\"\\nFINAL DATASET INFORMATION:\")\n",
    "print_df_info(data)\n",
    "\n",
    "# Final categorical columns\n",
    "print(f\"\\nFinal categorical columns: \\n{cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28c2578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_approx</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>tbp_lv_A</th>\n",
       "      <th>tbp_lv_Aext</th>\n",
       "      <th>tbp_lv_B</th>\n",
       "      <th>tbp_lv_Bext</th>\n",
       "      <th>tbp_lv_C</th>\n",
       "      <th>tbp_lv_Cext</th>\n",
       "      <th>tbp_lv_H</th>\n",
       "      <th>tbp_lv_Hext</th>\n",
       "      <th>...</th>\n",
       "      <th>tbp_lv_age_ratio_A</th>\n",
       "      <th>tbp_lv_age_ratio_B</th>\n",
       "      <th>tbp_lv_age_ratio_C</th>\n",
       "      <th>tbp_lv_age_ratio_H</th>\n",
       "      <th>tbp_lv_age_ratio_L</th>\n",
       "      <th>tbp_lv_age_contrast_A</th>\n",
       "      <th>tbp_lv_age_contrast_B</th>\n",
       "      <th>tbp_lv_age_contrast_C</th>\n",
       "      <th>tbp_lv_age_contrast_H</th>\n",
       "      <th>tbp_lv_age_contrast_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.243606</td>\n",
       "      <td>-0.100039</td>\n",
       "      <td>0.781787</td>\n",
       "      <td>1.901507</td>\n",
       "      <td>-0.572161</td>\n",
       "      <td>0.019702</td>\n",
       "      <td>-0.089553</td>\n",
       "      <td>0.779579</td>\n",
       "      <td>-1.270117</td>\n",
       "      <td>-1.714984</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.052154</td>\n",
       "      <td>-1.034448</td>\n",
       "      <td>-1.292997</td>\n",
       "      <td>0.397350</td>\n",
       "      <td>-0.677492</td>\n",
       "      <td>-1.262306</td>\n",
       "      <td>-2.066706</td>\n",
       "      <td>-1.737805</td>\n",
       "      <td>-0.589995</td>\n",
       "      <td>0.451596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.216008</td>\n",
       "      <td>3.040342</td>\n",
       "      <td>0.639352</td>\n",
       "      <td>0.612006</td>\n",
       "      <td>-0.314999</td>\n",
       "      <td>-0.265541</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>-0.003891</td>\n",
       "      <td>-0.878883</td>\n",
       "      <td>-0.809827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242773</td>\n",
       "      <td>-0.260195</td>\n",
       "      <td>-0.040549</td>\n",
       "      <td>-0.264462</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.100548</td>\n",
       "      <td>-0.221579</td>\n",
       "      <td>-0.024497</td>\n",
       "      <td>0.084260</td>\n",
       "      <td>0.515178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.040526</td>\n",
       "      <td>-0.144348</td>\n",
       "      <td>-1.120523</td>\n",
       "      <td>-0.813640</td>\n",
       "      <td>-1.853328</td>\n",
       "      <td>-1.896887</td>\n",
       "      <td>-1.874503</td>\n",
       "      <td>-1.850486</td>\n",
       "      <td>-0.799620</td>\n",
       "      <td>-0.719828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.674942</td>\n",
       "      <td>-0.558272</td>\n",
       "      <td>-0.555562</td>\n",
       "      <td>0.060420</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>-0.804103</td>\n",
       "      <td>-0.504319</td>\n",
       "      <td>-0.758010</td>\n",
       "      <td>-0.194606</td>\n",
       "      <td>-1.302287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.513799</td>\n",
       "      <td>3.056957</td>\n",
       "      <td>-0.896086</td>\n",
       "      <td>-0.341678</td>\n",
       "      <td>-1.976057</td>\n",
       "      <td>-1.263195</td>\n",
       "      <td>-1.853994</td>\n",
       "      <td>-1.166660</td>\n",
       "      <td>-1.267365</td>\n",
       "      <td>-0.665592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.658133</td>\n",
       "      <td>-2.426898</td>\n",
       "      <td>-1.977528</td>\n",
       "      <td>-1.151828</td>\n",
       "      <td>-3.540271</td>\n",
       "      <td>-0.885574</td>\n",
       "      <td>-2.008445</td>\n",
       "      <td>-1.959741</td>\n",
       "      <td>0.977343</td>\n",
       "      <td>4.682795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.878702</td>\n",
       "      <td>-0.753593</td>\n",
       "      <td>-0.301943</td>\n",
       "      <td>0.689301</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.108463</td>\n",
       "      <td>-0.131931</td>\n",
       "      <td>0.317644</td>\n",
       "      <td>0.341180</td>\n",
       "      <td>-0.594659</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.091516</td>\n",
       "      <td>-0.057567</td>\n",
       "      <td>-0.799372</td>\n",
       "      <td>1.302344</td>\n",
       "      <td>0.669620</td>\n",
       "      <td>-1.362797</td>\n",
       "      <td>-0.072026</td>\n",
       "      <td>-0.842768</td>\n",
       "      <td>-1.351153</td>\n",
       "      <td>-1.269032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20038</th>\n",
       "      <td>-0.580912</td>\n",
       "      <td>2.325864</td>\n",
       "      <td>-0.639393</td>\n",
       "      <td>-1.002371</td>\n",
       "      <td>-0.793558</td>\n",
       "      <td>-0.466514</td>\n",
       "      <td>-0.891116</td>\n",
       "      <td>-0.756467</td>\n",
       "      <td>-0.084248</td>\n",
       "      <td>0.777280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652382</td>\n",
       "      <td>-1.050440</td>\n",
       "      <td>-0.574232</td>\n",
       "      <td>-1.156930</td>\n",
       "      <td>-0.588853</td>\n",
       "      <td>0.347832</td>\n",
       "      <td>-0.780729</td>\n",
       "      <td>-0.614112</td>\n",
       "      <td>1.258421</td>\n",
       "      <td>0.087395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20039</th>\n",
       "      <td>0.148895</td>\n",
       "      <td>0.935678</td>\n",
       "      <td>0.508491</td>\n",
       "      <td>-0.235638</td>\n",
       "      <td>1.181675</td>\n",
       "      <td>1.576476</td>\n",
       "      <td>1.078110</td>\n",
       "      <td>1.206756</td>\n",
       "      <td>0.495405</td>\n",
       "      <td>1.135076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892264</td>\n",
       "      <td>-0.435458</td>\n",
       "      <td>-0.167400</td>\n",
       "      <td>-0.803593</td>\n",
       "      <td>1.211860</td>\n",
       "      <td>1.073282</td>\n",
       "      <td>-0.334872</td>\n",
       "      <td>0.070803</td>\n",
       "      <td>1.014452</td>\n",
       "      <td>-0.997257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20040</th>\n",
       "      <td>0.148895</td>\n",
       "      <td>2.519715</td>\n",
       "      <td>-0.230711</td>\n",
       "      <td>-0.867923</td>\n",
       "      <td>-1.207845</td>\n",
       "      <td>-0.733012</td>\n",
       "      <td>-1.008859</td>\n",
       "      <td>-0.935463</td>\n",
       "      <td>-1.004578</td>\n",
       "      <td>0.423217</td>\n",
       "      <td>...</td>\n",
       "      <td>1.091722</td>\n",
       "      <td>-1.484464</td>\n",
       "      <td>-0.350988</td>\n",
       "      <td>-2.109608</td>\n",
       "      <td>-0.312509</td>\n",
       "      <td>0.795889</td>\n",
       "      <td>-1.150024</td>\n",
       "      <td>-0.527351</td>\n",
       "      <td>2.169080</td>\n",
       "      <td>1.178810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20041</th>\n",
       "      <td>0.513799</td>\n",
       "      <td>4.496991</td>\n",
       "      <td>0.873258</td>\n",
       "      <td>0.974768</td>\n",
       "      <td>-2.044711</td>\n",
       "      <td>-1.380918</td>\n",
       "      <td>-0.953752</td>\n",
       "      <td>-0.656585</td>\n",
       "      <td>-3.195681</td>\n",
       "      <td>-2.201133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276345</td>\n",
       "      <td>-2.381744</td>\n",
       "      <td>-0.767713</td>\n",
       "      <td>-2.375442</td>\n",
       "      <td>-0.954453</td>\n",
       "      <td>0.089209</td>\n",
       "      <td>-1.937519</td>\n",
       "      <td>-0.873042</td>\n",
       "      <td>1.537911</td>\n",
       "      <td>1.338366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20042</th>\n",
       "      <td>0.513799</td>\n",
       "      <td>3.416966</td>\n",
       "      <td>2.833760</td>\n",
       "      <td>1.349885</td>\n",
       "      <td>-1.130470</td>\n",
       "      <td>-0.178034</td>\n",
       "      <td>0.674031</td>\n",
       "      <td>0.381723</td>\n",
       "      <td>-3.424225</td>\n",
       "      <td>-1.415057</td>\n",
       "      <td>...</td>\n",
       "      <td>1.140224</td>\n",
       "      <td>-2.250269</td>\n",
       "      <td>0.704518</td>\n",
       "      <td>-3.849980</td>\n",
       "      <td>0.092352</td>\n",
       "      <td>2.703163</td>\n",
       "      <td>-2.177016</td>\n",
       "      <td>0.864965</td>\n",
       "      <td>3.102487</td>\n",
       "      <td>0.013045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19030 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_approx  clin_size_long_diam_mm  tbp_lv_A  tbp_lv_Aext  tbp_lv_B  \\\n",
       "0        1.243606               -0.100039  0.781787     1.901507 -0.572161   \n",
       "1       -0.216008                3.040342  0.639352     0.612006 -0.314999   \n",
       "2       -2.040526               -0.144348 -1.120523    -0.813640 -1.853328   \n",
       "3        0.513799                3.056957 -0.896086    -0.341678 -1.976057   \n",
       "4        0.878702               -0.753593 -0.301943     0.689301  0.025826   \n",
       "...           ...                     ...       ...          ...       ...   \n",
       "20038   -0.580912                2.325864 -0.639393    -1.002371 -0.793558   \n",
       "20039    0.148895                0.935678  0.508491    -0.235638  1.181675   \n",
       "20040    0.148895                2.519715 -0.230711    -0.867923 -1.207845   \n",
       "20041    0.513799                4.496991  0.873258     0.974768 -2.044711   \n",
       "20042    0.513799                3.416966  2.833760     1.349885 -1.130470   \n",
       "\n",
       "       tbp_lv_Bext  tbp_lv_C  tbp_lv_Cext  tbp_lv_H  tbp_lv_Hext  ...  \\\n",
       "0         0.019702 -0.089553     0.779579 -1.270117    -1.714984  ...   \n",
       "1        -0.265541  0.020901    -0.003891 -0.878883    -0.809827  ...   \n",
       "2        -1.896887 -1.874503    -1.850486 -0.799620    -0.719828  ...   \n",
       "3        -1.263195 -1.853994    -1.166660 -1.267365    -0.665592  ...   \n",
       "4         0.108463 -0.131931     0.317644  0.341180    -0.594659  ...   \n",
       "...            ...       ...          ...       ...          ...  ...   \n",
       "20038    -0.466514 -0.891116    -0.756467 -0.084248     0.777280  ...   \n",
       "20039     1.576476  1.078110     1.206756  0.495405     1.135076  ...   \n",
       "20040    -0.733012 -1.008859    -0.935463 -1.004578     0.423217  ...   \n",
       "20041    -1.380918 -0.953752    -0.656585 -3.195681    -2.201133  ...   \n",
       "20042    -0.178034  0.674031     0.381723 -3.424225    -1.415057  ...   \n",
       "\n",
       "       tbp_lv_age_ratio_A  tbp_lv_age_ratio_B  tbp_lv_age_ratio_C  \\\n",
       "0               -1.052154           -1.034448           -1.292997   \n",
       "1               -0.242773           -0.260195           -0.040549   \n",
       "2               -0.674942           -0.558272           -0.555562   \n",
       "3               -0.658133           -2.426898           -1.977528   \n",
       "4               -1.091516           -0.057567           -0.799372   \n",
       "...                   ...                 ...                 ...   \n",
       "20038            0.652382           -1.050440           -0.574232   \n",
       "20039            0.892264           -0.435458           -0.167400   \n",
       "20040            1.091722           -1.484464           -0.350988   \n",
       "20041           -0.276345           -2.381744           -0.767713   \n",
       "20042            1.140224           -2.250269            0.704518   \n",
       "\n",
       "       tbp_lv_age_ratio_H  tbp_lv_age_ratio_L  tbp_lv_age_contrast_A  \\\n",
       "0                0.397350           -0.677492              -1.262306   \n",
       "1               -0.264462            0.012420               0.100548   \n",
       "2                0.060420            0.019373              -0.804103   \n",
       "3               -1.151828           -3.540271              -0.885574   \n",
       "4                1.302344            0.669620              -1.362797   \n",
       "...                   ...                 ...                    ...   \n",
       "20038           -1.156930           -0.588853               0.347832   \n",
       "20039           -0.803593            1.211860               1.073282   \n",
       "20040           -2.109608           -0.312509               0.795889   \n",
       "20041           -2.375442           -0.954453               0.089209   \n",
       "20042           -3.849980            0.092352               2.703163   \n",
       "\n",
       "       tbp_lv_age_contrast_B  tbp_lv_age_contrast_C  tbp_lv_age_contrast_H  \\\n",
       "0                  -2.066706              -1.737805              -0.589995   \n",
       "1                  -0.221579              -0.024497               0.084260   \n",
       "2                  -0.504319              -0.758010              -0.194606   \n",
       "3                  -2.008445              -1.959741               0.977343   \n",
       "4                  -0.072026              -0.842768              -1.351153   \n",
       "...                      ...                    ...                    ...   \n",
       "20038              -0.780729              -0.614112               1.258421   \n",
       "20039              -0.334872               0.070803               1.014452   \n",
       "20040              -1.150024              -0.527351               2.169080   \n",
       "20041              -1.937519              -0.873042               1.537911   \n",
       "20042              -2.177016               0.864965               3.102487   \n",
       "\n",
       "       tbp_lv_age_contrast_L  \n",
       "0                   0.451596  \n",
       "1                   0.515178  \n",
       "2                  -1.302287  \n",
       "3                   4.682795  \n",
       "4                  -1.269032  \n",
       "...                      ...  \n",
       "20038               0.087395  \n",
       "20039              -0.997257  \n",
       "20040               1.178810  \n",
       "20041               1.338366  \n",
       "20042               0.013045  \n",
       "\n",
       "[19030 rows x 101 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = data.select_dtypes(['number']).columns\n",
    "num_cols = num_cols[1:] # excluding 'target' column\n",
    "scaler = StandardScaler() # Z-Scaling features\n",
    "data[num_cols] = scaler.fit_transform(data[num_cols])\n",
    "data[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b84aa1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.ENCODE_CAT:    \n",
    "    category_encoder = OrdinalEncoder(\n",
    "        categories='auto', dtype=np.int16, \n",
    "        handle_unknown='use_encoded_value', \n",
    "        unknown_value=-2, encoded_missing_value=-1\n",
    "    )\n",
    "\n",
    "    data_encoded = category_encoder.fit_transform(data[cat_cols])\n",
    "    # Assign the transformed categories back to the DataFrame\n",
    "    for c, cat_col in enumerate(cat_cols):\n",
    "        data[cat_col] = data_encoded[:, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60f55c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(solution, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float = 0.80):\n",
    "    \"\"\"\n",
    "    Compute the competition-specific partial AUC score\n",
    "    Returns:\n",
    "        float: Partial AUC score scaled to the competition's range.\n",
    "    \"\"\"\n",
    "    # Ensure correct dtype\n",
    "    if not isinstance(solution, np.ndarray):\n",
    "        solution = solution.values\n",
    "    v_gt = abs(np.asarray(solution, dtype=np.int32) - 1)\n",
    "    v_pred = 1.0 - np.asarray(submission.values, dtype=np.float64)\n",
    "\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "\n",
    "    # scikit-learn partial AUC\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "\n",
    "    # Scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    partial_auc = (\n",
    "        0.5 * max_fpr**2\n",
    "        + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    )\n",
    "    return partial_auc\n",
    "\n",
    "\n",
    "def recall_metric(y_true: np.ndarray, y_pred: np.ndarray, threshold: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Compute recall score from probabilities using sklearn.\n",
    "\n",
    "    Returns:\n",
    "        float: Recall score.\n",
    "    \"\"\"\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "    return recall_score(y_true, y_pred_binary)\n",
    "\n",
    "\n",
    "def plot_cm(y_true: np.ndarray, y_pred: np.ndarray, threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix using sklearn & seaborn.\n",
    "\n",
    "    Returns:\n",
    "        matplotlib.figure.Figure: The confusion matrix plot.\n",
    "    \"\"\"\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred_binary)\n",
    "    labels = sorted(np.unique(y_true))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        cmap='RdYlBu',\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        cbar=True,\n",
    "        square=True,\n",
    "        annot_kws={\"size\": 16},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ada3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_oversample(X, y, sampling_strategy=CONFIG.SMOTE_RATIO, k_neighbors=CONFIG.K_NEIGHBORS, random_state=42):  \n",
    "    X = X.astype(np.float32)\n",
    "    y = y.astype(np.int16)  \n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy, k_neighbors=k_neighbors, random_state=random_state)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "732cffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    v1, v2 = int(df[df['target'] == 0].shape[0]*0.6), int(df[df['target'] == 1].shape[0]*0.4)\n",
    "    train = pd.concat(\n",
    "        [\n",
    "            df[df['target'] == 0].iloc[:v1],\n",
    "            df[df['target'] == 1].iloc[:v2]\n",
    "        ]\n",
    "    )\n",
    "    test = pd.concat(\n",
    "        [\n",
    "            df[df['target'] == 0].iloc[v1:],\n",
    "            df[df['target'] == 1].iloc[v2:]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return train.sample(frac=1, random_state=42), test.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fdaea9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e26a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import h5py\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86270bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 7689 images successfully\n",
      "⚠️ Skipped 0 corrupted/invalid images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 172ms/step\n",
      "AUC: 0.9951, Accuracy: 0.9839\n",
      "✅ Saved predictions to ensemble_predictions_subset10.csv\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# CONFIG\n",
    "# =====================================================\n",
    "TABULAR_PATH = \"subject_data.csv\"        # metadata csv\n",
    "HDF5_PATH = \"images.hdf5\"                # HDF5 file containing images\n",
    "TABULAR_MODEL_PATH = \"tabular_voting_model.pkl\"\n",
    "CNN_MODEL_PATH = \"full_model.h5\"\n",
    "IMG_SIZE = (224, 224)                    # resize target\n",
    "\n",
    "\n",
    "# def decode_jpeg(byte_data, size=(224, 224)):\n",
    "#     with Image.open(io.BytesIO(byte_data)) as img:\n",
    "#         img = img.convert(\"RGB\").resize(size)  # force same size\n",
    "#         return np.array(img)\n",
    "\n",
    "# =====================================================\n",
    "# 1. LOAD DATA (subset only first 10 rows)\n",
    "# =====================================================\n",
    "df = test_data\n",
    "\n",
    "# Subset\n",
    "data_subset = df.iloc[:test_data.shape[0]]\n",
    "\n",
    "# Extract target and groups\n",
    "target = data_subset[\"target\"].values\n",
    "groups = data_subset[\"patient_id\"].values\n",
    "\n",
    "# Tabular features (drop patient_id & target)\n",
    "X_tab = data_subset.drop(columns=[\"patient_id\", \"target\"])\n",
    "\n",
    "def decode_jpeg(byte_data, size=(224, 224)):\n",
    "    \"\"\"Decode JPEG bytes into a fixed-size RGB numpy array.\"\"\"\n",
    "    try:\n",
    "        with Image.open(io.BytesIO(byte_data)) as img:\n",
    "            img = img.convert(\"RGB\").resize(size)  # ensure RGB & fixed size\n",
    "            return np.array(img, dtype=np.uint8)\n",
    "    except Exception as e:\n",
    "        return None  # return None for bad images\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 2. LOAD IMAGES (robust with skip & log)\n",
    "# =====================================================\n",
    "valid_images = []\n",
    "valid_keys = []\n",
    "skipped_keys = []\n",
    "\n",
    "with h5py.File(HDF5_PATH, \"r\") as f:\n",
    "    keys = list(f.keys())[:test_data.shape[0]]  # take first 10k\n",
    "    for k in keys:\n",
    "        img = decode_jpeg(f[k][()], size=IMG_SIZE)\n",
    "        if img is not None and img.shape == (IMG_SIZE[0], IMG_SIZE[1], 3):\n",
    "            valid_images.append(img)\n",
    "            valid_keys.append(k)\n",
    "        else:\n",
    "            skipped_keys.append(k)\n",
    "\n",
    "X_img = np.stack(valid_images).astype(\"float32\") / 255.0\n",
    "\n",
    "print(f\"✅ Loaded {len(valid_images)} images successfully\")\n",
    "print(f\"⚠️ Skipped {len(skipped_keys)} corrupted/invalid images\")\n",
    "\n",
    "# Optional: save skipped keys for debugging\n",
    "if skipped_keys:\n",
    "    pd.DataFrame(skipped_keys, columns=[\"skipped_keys\"]).to_csv(\"skipped_images.csv\", index=False)\n",
    "    print(\"📝 Saved skipped image keys to skipped_images.csv\")\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# 3. MODELS (same as before)\n",
    "# =====================================================\n",
    "lgb_model = lgb.LGBMClassifier(**CONFIG.lgb_params)\n",
    "xgb_model = xgb.XGBClassifier(**CONFIG.xgb_params, base_score=0.5, eval_metric=\"auc\")\n",
    "\n",
    "tabular_model = VotingClassifier(\n",
    "    estimators=[('lgb', lgb_model), ('xgb', xgb_model)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cnn_model = load_model(CNN_MODEL_PATH)\n",
    "\n",
    "# =====================================================\n",
    "# 4. TRAIN & PREDICT WITHOUT CV\n",
    "# =====================================================\n",
    "# Train tabular model on all data\n",
    "tabular_model.fit(X_tab, target)\n",
    "tabular_preds = tabular_model.predict_proba(X_tab)[:, 1]\n",
    "\n",
    "# CNN predictions on all images\n",
    "cnn_preds = cnn_model.predict(X_img, batch_size=32).ravel()\n",
    "\n",
    "# Ensemble predictions\n",
    "final_preds = np.mean([tabular_preds, cnn_preds], axis=0)\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(target, final_preds)\n",
    "acc = accuracy_score(target, (final_preds >= 0.5).astype(int))\n",
    "print(f\"AUC: {auc:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# =====================================================\n",
    "# 5. SAVE RESULTS\n",
    "# =====================================================\n",
    "results = pd.DataFrame({\n",
    "    \"patient_id\": data_subset[\"patient_id\"],\n",
    "    \"target\": data_subset[\"target\"],\n",
    "    \"ensemble_prob\": final_preds,\n",
    "    \"ensemble_label\": (final_preds >= 0.5).astype(int)\n",
    "})\n",
    "results.to_csv(\"ensemble_predictions_subset10.csv\", index=False)\n",
    "print(\"✅ Saved predictions to ensemble_predictions_subset10.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6274ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>target</th>\n",
       "      <th>ensemble_prob</th>\n",
       "      <th>ensemble_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14313</th>\n",
       "      <td>IP_1741190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.152321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>IP_9853536</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18109</th>\n",
       "      <td>IP_6945752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18729</th>\n",
       "      <td>IP_8599446</td>\n",
       "      <td>0</td>\n",
       "      <td>0.338589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17563</th>\n",
       "      <td>IP_3026693</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17303</th>\n",
       "      <td>IP_2873124</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17475</th>\n",
       "      <td>IP_9301252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>IP_8154159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19957</th>\n",
       "      <td>IP_9453251</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19451</th>\n",
       "      <td>IP_8557750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.278147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  target  ensemble_prob  ensemble_label\n",
       "14313  IP_1741190       0       0.152321               0\n",
       "14992  IP_9853536       0       0.068105               0\n",
       "18109  IP_6945752       0       0.018925               0\n",
       "18729  IP_8599446       0       0.338589               0\n",
       "17563  IP_3026693       0       0.253439               0\n",
       "...           ...     ...            ...             ...\n",
       "17303  IP_2873124       0       0.025228               0\n",
       "17475  IP_9301252       0       0.059234               0\n",
       "12696  IP_8154159       0       0.084775               0\n",
       "19957  IP_9453251       1       0.548026               1\n",
       "19451  IP_8557750       0       0.278147               0\n",
       "\n",
       "[7689 rows x 4 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec9d3fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(results[\"target\"], results[\"ensemble_label\"])\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "            yticklabels=[\"True 0\", \"True 1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c165cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9838730654181298\n",
      "Precision: 1.0\n",
      "Recall: 0.4585152838427948\n",
      "F1: 0.6287425149700598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(results[\"target\"], results[\"ensemble_label\"]))\n",
    "print(\"Precision:\", precision_score(results[\"target\"], results[\"ensemble_label\"]))\n",
    "print(\"Recall:\", recall_score(results[\"target\"], results[\"ensemble_label\"]))\n",
    "print(\"F1:\", f1_score(results[\"target\"], results[\"ensemble_label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63d4e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial AUC score: 0.03693548387096771\n"
     ]
    }
   ],
   "source": [
    "score = comp_score(\n",
    "    solution=np.asarray(results[\"target\"]).astype(np.float32),          # true labels\n",
    "    submission=results[[\"ensemble_label\"]], # must be DataFrame, not Series\n",
    "    row_id_column_name=\"ensemble_label\"\n",
    ")\n",
    "\n",
    "print(\"Partial AUC score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea40d498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
